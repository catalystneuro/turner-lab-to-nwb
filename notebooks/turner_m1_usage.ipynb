{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner Lab M1 MPTP Dataset - NWB Usage Guide\n",
    "\n",
    "**Dataset Overview:**\n",
    "This dataset contains single-unit electrophysiology recordings from primary motor cortex (M1) of parkinsonian macaque monkeys performing flexion/extension motor tasks. The data investigates motor encoding deficits in MPTP-induced parkinsonism, comparing pyramidal tract neurons (PTNs) versus corticostriatal neurons (CSNs).\n",
    "\n",
    "**Key Features:**\n",
    "- **Single-unit recordings**: Spike times and waveforms from M1 neurons\n",
    "- **Motor behavior**: Flexion/extension task with analog kinematics\n",
    "- **Cell type identification**: Antidromic stimulation to classify PTNs vs CSNs\n",
    "- **Disease model**: MPTP-treated parkinsonian macaque monkeys\n",
    "- **Electrode mapping**: Systematic cortical penetrations with stereotactic coordinates\n",
    "\n",
    "**Data Organization:**\n",
    "- Each NWB file represents one recording session from one penetration depth\n",
    "- Session IDs follow pattern: `{subject_id}++{FileName}++{PreMPTP|PostMPTP}++Depth{depth_um}um++{YearMonthDay}`\n",
    "- Example: `V++{v0502}++PostMPTP++Depth19180um++20000121` indicates monkey V, post-MPTP condition, 19.18mm depth, recorded Jan 21, 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming NWB Files from DANDI \n",
    "\n",
    "We recommend using the DANDI Python client to access the NWB files directly from the DANDI archive without downloading them locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import remfile\n",
    "from pynwb import NWBHDF5IO\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "# Connect to DANDI and get the dandiset\n",
    "dandiset_id = \"001636\"\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(dandiset_id, \"draft\")\n",
    "\n",
    "# Get all assets - users can filter this list to select any session\n",
    "assets = dandiset.get_assets()\n",
    "assets_list = list(assets)\n",
    "print(f\"Total assets in dandiset: {len(assets_list)}\")\n",
    "\n",
    "# Filter for NWB files only\n",
    "nwb_assets = [a for a in assets_list if a.path.endswith(\".nwb\")]\n",
    "print(f\"NWB files: {len(nwb_assets)}\")\n",
    "\n",
    "# We select this specific session because it is \"complete\" - it has all available data types:\n",
    "# - 2 PTNs (pyramidal tract neurons) identified via antidromic stimulation\n",
    "# - EMG recordings from multiple arm muscles\n",
    "# - LFP data\n",
    "# - Perturbation trials (52 out of 80 total trials)\n",
    "# - Balanced flexion/extension movements (40 each)\n",
    "#\n",
    "# The only missing feature is receptive field locations (not recorded for these units).\n",
    "# See dandiset_session_metadata.csv for a full inventory of all 298 sessions.\n",
    "asset_path = \"sub-V/sub-V_ses-V++v5811++PostMPTP++Depth18300um++20000331_behavior+ecephys.nwb\"\n",
    "asset = next(a for a in nwb_assets if a.path == asset_path)\n",
    "print(f\"Selected asset: {asset.path}\")\n",
    "\n",
    "# Stream the NWB file directly from DANDI (no download required)\n",
    "s3_url = asset.get_content_url(follow_redirects=1, strip_query=False)\n",
    "file_system = remfile.File(s3_url)\n",
    "file = h5py.File(file_system, mode=\"r\")\n",
    "\n",
    "io = NWBHDF5IO(file=file)\n",
    "nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fist, we can visualize the HTML representation of the nwbfile to get an overview of its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Trial Structure\n",
    "\n",
    "The behavioral task is a visuomotor step-tracking paradigm where monkeys make rapid elbow flexion/extension movements to capture visual targets. Each trial follows a stereotyped sequence of events that we can examine through the trials table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.trials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trials are stored as a table in NWB. We can convert it to a pandas DataFrame to explore the structure of the trial events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_df = nwbfile.trials.to_dataframe()\n",
    "trials_df.sample(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial Event Sequence\n",
    "\n",
    "Let's examine the key columns that define the temporal structure of each trial:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"start_time\",\n",
    "    \"center_target_appearance_time\",\n",
    "    \"lateral_target_appearance_time\",\n",
    "    \"cursor_departure_time\",\n",
    "    \"movement_type\",\n",
    "    \"reward_time\",\n",
    "]\n",
    "trials_df[columns].head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each trial progresses through distinct phases:\n",
    "\n",
    "1. **Trial start**: Recording begins with a variable baseline period\n",
    "2. **Center target appearance**: A center target appears on screen, cueing the monkey to align the cursor and hold\n",
    "3. **Center hold period**: The monkey maintains position for 1-2 seconds (randomized to prevent anticipation)\n",
    "4. **Lateral target appearance (go cue)**: A peripheral target appears, signaling the monkey to move\n",
    "5. **Cursor departure**: The monkey initiates movement, exiting the center zone\n",
    "6. **Movement execution**: Rapid ballistic movement toward the target (flexion or extension)\n",
    "7. **Reward**: Liquid reward delivered upon successful target acquisition\n",
    "\n",
    "The time differences between these events reveal reaction times, movement durations, and other behaviorally relevant measures.\n",
    "\n",
    "To graphically understand the trial structure, we can look at the following visualization that is using the data in the NWB file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trial_structure_plot import plot_trial_structure\n",
    "\n",
    "plot_trial_structure(trials_df, max_trials=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization above shows the temporal structure of individual trials as horizontal stacked bars. Each row represents one trial, with colored segments indicating different task phases:\n",
    "\n",
    "- **Baseline** (gray): Variable waiting period before the task begins\n",
    "- **Holding at Center** (teal): The monkey maintains cursor position at the center target, waiting for the go cue\n",
    "- **Time to React** (yellow): The interval between go cue (lateral target appearance) and cursor departure from the center zone\n",
    "- **Movement** (coral): Active movement execution toward the peripheral target\n",
    "- **Holding at Target** (purple): The monkey holds position at the target before reward delivery\n",
    "- **Post-Reward** (sky blue): Brief period after reward before trial ends\n",
    "\n",
    "Trials labeled \"Aborted\" were terminated early (the monkey broke fixation before the go cue). Notice the consistent structure across trials, with the main variability coming from the randomized center hold duration (1-2 seconds) and individual differences in reaction time and movement speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Kinematic Measures\n",
    "\n",
    "In addition to trial event times, the trials table includes derived kinematic parameters computed from post-hoc analysis of the elbow angle velocity trace. These measures characterize the movement itself:\n",
    "\n",
    "| Column | Description | Units |\n",
    "|--------|-------------|-------|\n",
    "| `derived_movement_onset_time` | Time when movement began (detected from velocity trace) | seconds |\n",
    "| `derived_movement_end_time` | Time when movement ended (velocity returned to baseline) | seconds |\n",
    "| `derived_peak_velocity` | Maximum angular velocity during the movement | degrees/second |\n",
    "| `derived_peak_velocity_time` | Time of peak velocity | seconds |\n",
    "| `derived_movement_amplitude` | Total angular displacement (end position - start position) | degrees |\n",
    "| `derived_end_position` | Final elbow angle at movement end | degrees |\n",
    "\n",
    "The \"derived\" prefix indicates these values were computed offline from kinematic analysis, not recorded directly during the experiment. The detection algorithm used position, velocity, and duration criteria (exact parameters not documented in source data).\n",
    "\n",
    "**Sign conventions:**\n",
    "- Positive velocities and amplitudes indicate extension movements\n",
    "- Negative velocities and amplitudes indicate flexion movements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access derived kinematic measures\n",
    "kinematic_columns = [\n",
    "    'derived_movement_onset_time',\n",
    "    'derived_movement_end_time',\n",
    "    'derived_peak_velocity',\n",
    "    'derived_peak_velocity_time',\n",
    "    'derived_movement_amplitude',\n",
    "    'derived_end_position',\n",
    "    'movement_type'\n",
    "]\n",
    "trials_df[kinematic_columns].head(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute commonly used derived measures\n",
    "# Note: Some trials may have NaN values if kinematic detection failed\n",
    "\n",
    "# Movement duration (from movement onset to movement end)\n",
    "trials_df['movement_duration'] = (\n",
    "    trials_df['derived_movement_end_time'] - trials_df['derived_movement_onset_time']\n",
    ")\n",
    "\n",
    "# Reaction time (from go cue to cursor departure)\n",
    "trials_df['reaction_time'] = (\n",
    "    trials_df['cursor_departure_time'] - trials_df['lateral_target_appearance_time']\n",
    ")\n",
    "\n",
    "# Filter to complete trials only\n",
    "complete_trials = trials_df.dropna(subset=['derived_movement_end_time'])\n",
    "\n",
    "print(f\"Complete trials with kinematic data: {len(complete_trials)} / {len(trials_df)}\")\n",
    "print(f\"\\nMovement duration: {complete_trials['movement_duration'].mean()*1000:.0f} +/- {complete_trials['movement_duration'].std()*1000:.0f} ms\")\n",
    "print(f\"Reaction time: {complete_trials['reaction_time'].mean()*1000:.0f} +/- {complete_trials['reaction_time'].std()*1000:.0f} ms\")\n",
    "print(f\"Peak velocity: {complete_trials['derived_peak_velocity'].abs().mean():.1f} +/- {complete_trials['derived_peak_velocity'].abs().std():.1f} deg/s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Torque Perturbation Trials\n",
    "\n",
    "A subset of trials included brief mechanical perturbations delivered via the torque motor during the center hold period. These perturbations caused rapid muscle stretch, allowing researchers to study proprioceptive responses in M1 neurons (see Pasquereau & Turner, 2013).\n",
    "\n",
    "**Note:** Not all sessions include perturbation trials. Sessions without perturbations will have `torque_perturbation_type = \"none\"` for all trials and `torque_perturbation_onset_time = NaN`.\n",
    "\n",
    "| Column | Description | Values |\n",
    "|--------|-------------|--------|\n",
    "| `torque_perturbation_type` | Direction of the perturbation | `\"flexion\"`, `\"extension\"`, or `\"none\"` |\n",
    "| `torque_perturbation_onset_time` | Time when perturbation was delivered | seconds (NaN if no perturbation) |\n",
    "\n",
    "**Perturbation characteristics (when present):**\n",
    "- Delivered 150-500 ms after center target appearance (during hold period)\n",
    "- Brief torque pulse causing ~5-10 degree displacement\n",
    "- Direction (flexion/extension) was independent of the upcoming movement direction\n",
    "- Present in approximately 65% of trials in sessions that included perturbations\n",
    "\n",
    "**Scientific purpose:** These trials enabled analysis of how M1 neurons respond to passive muscle stretch, separate from active movement. The muscle stretch study found that PTNs showed degraded directional selectivity to perturbations in the parkinsonian state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access torque perturbation data\n",
    "perturbation_columns = ['torque_perturbation_type', 'torque_perturbation_onset_time', 'movement_type']\n",
    "trials_df[perturbation_columns].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze perturbation trial distribution\n",
    "# Note: Not all sessions include perturbation trials. Sessions without perturbations\n",
    "# will have torque_perturbation_type = \"none\" for all trials.\n",
    "\n",
    "perturbation_counts = trials_df['torque_perturbation_type'].value_counts()\n",
    "n_perturbation_trials = len(trials_df[trials_df['torque_perturbation_type'] != 'none'])\n",
    "\n",
    "# Check if this session has perturbation data\n",
    "if n_perturbation_trials == 0:\n",
    "    print(\"This session does not include torque perturbation trials.\")\n",
    "    print(\"All trials have torque_perturbation_type = 'none'\")\n",
    "else:\n",
    "    print(f\"This session includes perturbation trials ({n_perturbation_trials} / {len(trials_df)} trials)\\n\")\n",
    "    print(\"Perturbation trial counts:\")\n",
    "    for ptype, count in perturbation_counts.items():\n",
    "        print(f\"  {ptype}: {count} trials ({100*count/len(trials_df):.1f}%)\")\n",
    "    \n",
    "    # Cross-tabulate perturbation direction vs movement direction\n",
    "    print(\"\\nPerturbation direction vs Movement direction:\")\n",
    "    print(trials_df.groupby(['torque_perturbation_type', 'movement_type']).size().unstack(fill_value=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Monitoring Stimulation\n",
    "\n",
    "In some recording sessions, single antidromic stimulation pulses were delivered early in certain trials to activate otherwise silent neurons and monitor unit isolation. This was particularly important for intratelencephalic-type (IT) cortical neurons (including corticostriatal neurons), which have very low spontaneous firing rates.\n",
    "\n",
    "**Background:** Some neurons rarely spike spontaneously but can be reliably activated by antidromic stimulation from their projection target (striatum, thalamus, or cerebral peduncle). Delivering occasional stimulation pulses during recording confirmed that the unit remained well-isolated throughout the session.\n",
    "\n",
    "| Column | Description | Values |\n",
    "|--------|-------------|--------|\n",
    "| `isolation_monitoring_stim_time` | Time when stimulation pulse was delivered | seconds (NaN if no stimulation in that trial) |\n",
    "| `isolation_monitoring_stim_site` | Anatomical target of the stimulation | `\"Str\"` (striatum), `\"Thal\"` (thalamus), `\"Ped\"` (peduncle), or empty string |\n",
    "\n",
    "**Characteristics:**\n",
    "- Stimulation pulses delivered ~244-245 ms after trial start (early in the baseline period)\n",
    "- Present in approximately 43% of sessions (171 out of 400 session files)\n",
    "- Most commonly targeting thalamus (117 sessions), followed by striatum (51 sessions)\n",
    "- When present, stimulation typically delivered in a subset of trials within the session\n",
    "\n",
    "**Note:** If you observe spike times that appear suspiciously constant across trials (~245-256 ms after trial start), these likely reflect antidromically-evoked spikes from isolation monitoring, not spontaneous activity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access isolation monitoring stimulation data\n",
    "stim_columns = ['isolation_monitoring_stim_time', 'isolation_monitoring_stim_site', 'start_time']\n",
    "trials_df[stim_columns].head(n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this session has isolation monitoring stimulation\n",
    "stim_trials = trials_df[trials_df['isolation_monitoring_stim_time'].notna()]\n",
    "n_stim_trials = len(stim_trials)\n",
    "\n",
    "if n_stim_trials == 0:\n",
    "    print(\"This session does not include isolation monitoring stimulation.\")\n",
    "    print(\"All trials have isolation_monitoring_stim_time = NaN\")\n",
    "else:\n",
    "    print(f\"This session includes isolation monitoring stimulation ({n_stim_trials} / {len(trials_df)} trials)\\n\")\n",
    "    \n",
    "    # Get stimulation site (should be consistent within session)\n",
    "    stim_site = stim_trials['isolation_monitoring_stim_site'].iloc[0]\n",
    "    print(f\"Stimulation site: {stim_site}\")\n",
    "    \n",
    "    # Calculate timing relative to trial start\n",
    "    stim_trials = stim_trials.copy()\n",
    "    stim_trials['stim_time_relative'] = (\n",
    "        stim_trials['isolation_monitoring_stim_time'] - stim_trials['start_time']\n",
    "    )\n",
    "    \n",
    "    mean_stim_time = stim_trials['stim_time_relative'].mean() * 1000  # Convert to ms\n",
    "    std_stim_time = stim_trials['stim_time_relative'].std() * 1000\n",
    "    \n",
    "    print(f\"Stimulation timing: {mean_stim_time:.1f} +/- {std_stim_time:.1f} ms after trial start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Neurons/Units Spikes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units_df = nwbfile.units.to_dataframe()\n",
    "units_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquisition Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile.acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrode Configuration and Recording Setup\n",
    "\n",
    "The dataset includes both recording and stimulation electrodes with detailed anatomical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine electrode configuration\n",
    "from pynwb import read_nwb\n",
    "\n",
    "electrodes_df = nwbfile.electrodes.to_dataframe()\n",
    "print(\"Electrode Configuration:\")\n",
    "print(f\"Total electrodes: {len(electrodes_df)}\")\n",
    "print(f\"Recording electrodes: {len(electrodes_df[~electrodes_df['is_stimulation']])}\")\n",
    "print(f\"Stimulation electrodes: {len(electrodes_df[electrodes_df['is_stimulation']])}\")\n",
    "\n",
    "print(\"\\nRecording electrode details:\")\n",
    "recording_electrode = electrodes_df[~electrodes_df['is_stimulation']].iloc[0]\n",
    "print(f\"  Chamber coordinates: A/P={recording_electrode['chamber_grid_ap_mm']:.2f}mm, M/L={recording_electrode['chamber_grid_ml_mm']:.2f}mm\")\n",
    "print(f\"  Insertion depth: {recording_electrode['chamber_insertion_depth_mm']:.2f}mm\")\n",
    "print(f\"  Recording site index: {recording_electrode['recording_site_index']}\")\n",
    "print(f\"  Recording session index: {recording_electrode['recording_session_index']}\")\n",
    "\n",
    "print(\"\\nStimulation electrodes:\")\n",
    "stim_electrodes = electrodes_df[electrodes_df['is_stimulation']]\n",
    "for _, electrode in stim_electrodes.iterrows():\n",
    "    print(f\"  {electrode['location']}: {electrode['stim_notes']}\")\n",
    "\n",
    "# Display electrode table\n",
    "electrodes_df[['location', 'group_name', 'is_stimulation', 'chamber_grid_ap_mm', 'chamber_grid_ml_mm', 'chamber_insertion_depth_mm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Structure and Motor Behavior\n",
    "\n",
    "First, let's examine the experimental trials which provide the temporal structure for all other analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trial structure\n",
    "trials_df = nwbfile.trials.to_dataframe()\n",
    "print(f\"Number of trials: {len(trials_df)}\")\n",
    "print(\"\\nTrial metadata columns:\")\n",
    "for col in trials_df.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "# Display trials table\n",
    "trials_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Unit Activity Analysis\n",
    "\n",
    "Now let's examine the single-unit spike data and how it relates to the trial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine units table\n",
    "units_df = nwbfile.units.to_dataframe()\n",
    "units_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trialized Spike Analysis\n",
    "\n",
    "Let's analyze spikes within the context of behavioral trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialized spike analysis\n",
    "unit_id = 0\n",
    "spike_times = nwbfile.units['spike_times'][unit_id]\n",
    "\n",
    "print(f\"Unit {unit_id} analysis:\")\n",
    "print(f\"  Total spikes: {len(spike_times)}\")\n",
    "print(f\"  Recording duration: {spike_times[-1] - spike_times[0]:.2f} seconds\")\n",
    "print(f\"  Mean firing rate: {len(spike_times) / (spike_times[-1] - spike_times[0]):.2f} Hz\")\n",
    "\n",
    "# Create trial-aligned spike raster\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Trial-aligned spike raster\n",
    "trial_spikes = []\n",
    "for trial_idx, trial in trials_df.iterrows():\n",
    "    trial_start = trial['start_time']\n",
    "    trial_stop = trial['stop_time']\n",
    "    \n",
    "    # Find spikes within this trial\n",
    "    trial_spike_times = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "    \n",
    "    # Convert to trial-relative times\n",
    "    relative_spike_times = trial_spike_times - trial_start\n",
    "    trial_spikes.append(relative_spike_times)\n",
    "    \n",
    "    # Plot spikes for this trial\n",
    "    if len(relative_spike_times) > 0:\n",
    "        ax1.scatter(relative_spike_times, np.full(len(relative_spike_times), trial_idx), \n",
    "                   s=1, color='black', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Time relative to trial start (s)')\n",
    "ax1.set_ylabel('Trial number')\n",
    "ax1.set_title('Trial-aligned spike raster')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# PSTH across trials\n",
    "# Bin spikes relative to trial start\n",
    "bin_size = 0.1  # 100ms bins\n",
    "max_trial_duration = trials_df['stop_time'].max() - trials_df['start_time'].min()\n",
    "bins = np.arange(0, max_trial_duration + bin_size, bin_size)\n",
    "\n",
    "# Collect all trial-relative spike times\n",
    "all_relative_spikes = np.concatenate([spikes for spikes in trial_spikes if len(spikes) > 0])\n",
    "\n",
    "if len(all_relative_spikes) > 0:\n",
    "    counts, _ = np.histogram(all_relative_spikes, bins=bins)\n",
    "    firing_rate = counts / (bin_size * len(trials_df))  # Average across trials\n",
    "    \n",
    "    ax2.plot(bins[:-1], firing_rate, linewidth=2)\n",
    "    ax2.set_xlabel('Time relative to trial start (s)')\n",
    "    ax2.set_ylabel('Firing rate (Hz)')\n",
    "    ax2.set_title('Peri-stimulus time histogram (PSTH)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nTrialized analysis:\")\n",
    "print(f\"  Trials with spikes: {sum(1 for spikes in trial_spikes if len(spikes) > 0)}/{len(trials_df)}\")\n",
    "print(f\"  Mean spikes per trial: {np.mean([len(spikes) for spikes in trial_spikes]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trialized Kinematic Analysis (TimeSeriesElbowVelocity)\n",
    "\n",
    "Now let's examine how the kinematic data aligns with trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialized kinematic analysis\n",
    "# Find TimeSeriesElbowVelocity\n",
    "elbow_velocity_series = nwbfile.acquisition['TimeSeriesElbowVelocity']\n",
    "\n",
    "print(f\"Kinematic data: {elbow_velocity_series.name}\")\n",
    "print(f\"  Description: {elbow_velocity_series.description}\")\n",
    "print(f\"  Data shape: {elbow_velocity_series.data.shape}\")\n",
    "print(f\"  Sampling rate: {elbow_velocity_series.rate} Hz\")\n",
    "print(f\"  Duration: {elbow_velocity_series.data.shape[0] / elbow_velocity_series.rate:.2f} seconds\")\n",
    "\n",
    "# Extract trial-aligned kinematic data\n",
    "kinematic_data = elbow_velocity_series.data[:]\n",
    "sampling_rate = elbow_velocity_series.rate\n",
    "\n",
    "# Plot trial-aligned kinematics\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "trial_kinematics = []\n",
    "for trial_idx, trial in trials_df.iterrows():\n",
    "    trial_start = trial['start_time']\n",
    "    trial_stop = trial['stop_time']\n",
    "    \n",
    "    # Convert trial times to sample indices\n",
    "    start_sample = int(trial_start * sampling_rate)\n",
    "    stop_sample = int(trial_stop * sampling_rate)\n",
    "    \n",
    "    # Extract kinematic data for this trial\n",
    "    trial_data = kinematic_data[start_sample:stop_sample]\n",
    "    trial_time = np.arange(len(trial_data)) / sampling_rate\n",
    "    \n",
    "    trial_kinematics.append(trial_data)\n",
    "    \n",
    "    # Plot individual trial (show first 10 trials)\n",
    "    if trial_idx < 10:\n",
    "        ax1.plot(trial_time, trial_data, alpha=0.7, linewidth=1, label=f'Trial {trial_idx+1}')\n",
    "\n",
    "ax1.set_xlabel('Time relative to trial start (s)')\n",
    "ax1.set_ylabel('Elbow Velocity')\n",
    "ax1.set_title('Trial-aligned Elbow Velocity (first 10 trials)')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average across trials\n",
    "# Find minimum trial length for alignment\n",
    "min_trial_length = min(len(trial_data) for trial_data in trial_kinematics)\n",
    "\n",
    "# Truncate all trials to minimum length and average\n",
    "aligned_trials = np.array([trial_data[:min_trial_length] for trial_data in trial_kinematics])\n",
    "mean_kinematic = np.mean(aligned_trials, axis=0)\n",
    "std_kinematic = np.std(aligned_trials, axis=0)\n",
    "\n",
    "time_axis = np.arange(min_trial_length) / sampling_rate\n",
    "\n",
    "ax2.plot(time_axis, mean_kinematic, 'b-', linewidth=2, label='Mean')\n",
    "ax2.fill_between(time_axis, \n",
    "                mean_kinematic - std_kinematic, \n",
    "                mean_kinematic + std_kinematic, \n",
    "                alpha=0.3, color='blue', label='±1 SD')\n",
    "ax2.set_xlabel('Time relative to trial start (s)')\n",
    "ax2.set_ylabel('Elbow Velocity')\n",
    "ax2.set_title('Average trial-aligned Elbow Velocity')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nTrialized kinematic analysis:\")\n",
    "print(f\"  Number of trials: {len(trial_kinematics)}\")\n",
    "print(f\"  Average trial duration: {np.mean([len(trial)/sampling_rate for trial in trial_kinematics]):.2f} seconds\")\n",
    "print(f\"  Kinematic range: {np.min(kinematic_data):.2f} to {np.max(kinematic_data):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform Analysis\n",
    "\n",
    "Examine spike waveform characteristics for unit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spike waveforms\n",
    "unit_id = 0\n",
    "\n",
    "# Get waveform data\n",
    "waveform_mean = nwbfile.units['waveform_mean'][unit_id]\n",
    "waveform_sd = nwbfile.units['waveform_sd'][unit_id]\n",
    "\n",
    "# Create time axis (20kHz sampling, 1.6ms window)\n",
    "sampling_rate = 20000  # Hz\n",
    "n_samples = len(waveform_mean)\n",
    "time_axis = np.arange(n_samples) / sampling_rate * 1000  # Convert to milliseconds\n",
    "\n",
    "# Plot waveform with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_axis, waveform_mean, 'b-', linewidth=2, label='Mean waveform')\n",
    "plt.fill_between(time_axis, \n",
    "                    waveform_mean - waveform_sd, \n",
    "                    waveform_mean + waveform_sd, \n",
    "                    alpha=0.3, color='blue', label='±1 SD')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (μV)')\n",
    "plt.title(f'Unit {unit_id} - Mean Spike Waveform')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add waveform characteristics\n",
    "duration = nwbfile.units['waveform_duration_ms'][unit_id]\n",
    "cell_type = nwbfile.units['cell_type'][unit_id]\n",
    "\n",
    "plt.text(0.7, 0.95, f'Duration: {duration:.2f} ms', \n",
    "        transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.text(0.7, 0.85, f'Cell type: {cell_type}', \n",
    "        transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antidromic Stimulation Analysis\n",
    "\n",
    "Examine the antidromic stimulation data used for cell type identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze antidromic stimulation data\n",
    "antidromic_module = nwbfile.processing['antidromic_identification']\n",
    "print(f\"Antidromic identification module found\")\n",
    "print(f\"Description: {antidromic_module.description}\")\n",
    "\n",
    "# Find stimulation and response series\n",
    "stim_series = []\n",
    "response_series = []\n",
    "\n",
    "for name, obj in antidromic_module.data_interfaces.items():\n",
    "    if 'Stimulation' in name:\n",
    "        stim_series.append((name, obj))\n",
    "    elif 'Response' in name:\n",
    "        response_series.append((name, obj))\n",
    "\n",
    "print(f\"\\\\nFound {len(stim_series)} stimulation series and {len(response_series)} response series\")\n",
    "\n",
    "# Plot one stimulation-response pair\n",
    "stim_name, stim_data = stim_series[0]\n",
    "resp_name, resp_data = response_series[0]\n",
    "\n",
    "print(f\"\\\\nAnalyzing: {stim_name} and {resp_name}\")\n",
    "\n",
    "# Get a small segment for visualization (first 5 sweeps)\n",
    "n_samples_per_sweep = 1000  # 50ms at 20kHz\n",
    "n_sweeps_to_plot = 5\n",
    "\n",
    "stim_segment = stim_data.data[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "resp_segment = resp_data.data[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "time_segment = stim_data.timestamps[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot stimulation current\n",
    "ax1.plot(time_segment, stim_segment * 1e6, 'r-', linewidth=1)  # Convert to μA\n",
    "ax1.set_ylabel('Stimulation Current (μA)')\n",
    "ax1.set_title(f'{stim_name} - First {n_sweeps_to_plot} sweeps')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot neural response\n",
    "ax2.plot(time_segment, resp_segment * 1e6, 'b-', linewidth=1)  # Convert to μV\n",
    "ax2.set_ylabel('Neural Response (μV)')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_title(f'{resp_name} - First {n_sweeps_to_plot} sweeps')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Stimulation data shape: {stim_data.data.shape}\")\n",
    "print(f\"Response data shape: {resp_data.data.shape}\")\n",
    "print(f\"Stimulation placed at: {stim_data.timestamps[0]:.1f} seconds after session start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Data Analysis: Spike-Triggered Averages\n",
    "\n",
    "Demonstrate how to combine multiple data streams for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spike-triggered average of kinematic data\n",
    "unit_id = 0\n",
    "spike_times = nwbfile.units['spike_times'][unit_id]\n",
    "\n",
    "# Get kinematic data\n",
    "kinematic_series = nwbfile.acquisition['TimeSeriesElbowVelocity']\n",
    "\n",
    "# Parameters for spike-triggered average\n",
    "window_size = 0.5  # ±500ms around each spike\n",
    "sampling_rate = kinematic_series.rate\n",
    "window_samples = int(window_size * sampling_rate)\n",
    "\n",
    "# Get kinematic data\n",
    "kinematic_data = kinematic_series.data[:]\n",
    "\n",
    "# Extract windows around spikes\n",
    "sta_windows = []\n",
    "\n",
    "for spike_time in spike_times:\n",
    "    spike_sample = int(spike_time * sampling_rate)\n",
    "    \n",
    "    # Check if window fits within data\n",
    "    if (spike_sample - window_samples >= 0 and \n",
    "        spike_sample + window_samples < len(kinematic_data)):\n",
    "        \n",
    "        window = kinematic_data[spike_sample - window_samples:spike_sample + window_samples + 1]\n",
    "        sta_windows.append(window)\n",
    "\n",
    "sta_windows = np.array(sta_windows)\n",
    "\n",
    "# Calculate mean and standard error\n",
    "sta_mean = np.mean(sta_windows, axis=0)\n",
    "sta_sem = np.std(sta_windows, axis=0) / np.sqrt(len(sta_windows))\n",
    "\n",
    "# Create time axis\n",
    "time_axis = np.linspace(-window_size, window_size, len(sta_mean))\n",
    "\n",
    "# Plot spike-triggered average\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_axis, sta_mean, 'b-', linewidth=2, label='Mean')\n",
    "plt.fill_between(time_axis, \n",
    "               sta_mean - sta_sem, \n",
    "               sta_mean + sta_sem, \n",
    "               alpha=0.3, color='blue', label='±SEM')\n",
    "\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.7, label='Spike time')\n",
    "plt.xlabel('Time relative to spike (s)')\n",
    "plt.ylabel('Elbow Velocity')\n",
    "plt.title(f'Spike-Triggered Average (Unit {unit_id}, n={len(sta_windows)} spikes)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Analyzed {len(sta_windows)} spikes out of {len(spike_times)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the key data types and analysis approaches for the Turner Lab M1 MPTP dataset:\n",
    "\n",
    "**Data Types Covered:**\n",
    "1. **Electrode configuration**: Recording and stimulation electrode setup with anatomical coordinates\n",
    "2. **Single-unit activity**: Spike times, waveforms, and cell type classification\n",
    "3. **Motor behavior**: Trial structure and analog kinematic recordings\n",
    "4. **Antidromic stimulation**: Electrical stimulation protocols for cell type identification\n",
    "5. **Cross-modal analysis**: Combining spike times with kinematic data\n",
    "\n",
    "**Key Features:**\n",
    "- All temporal data maintains original accuracy within each session\n",
    "- Systematic electrode mapping with chamber-relative coordinates\n",
    "- Cell type identification through antidromic stimulation\n",
    "- Motor task data for studying parkinsonian deficits\n",
    "- Rich metadata for experimental context\n",
    "\n",
    "**Temporal Limitations (Important):**\n",
    "- Session start times are set to midnight with systematic offsets for same-day recordings\n",
    "- Inter-trial intervals use fixed 3-second separation (not original behavioral timing)\n",
    "- All relative timing within sessions maintains original accuracy\n",
    "\n",
    "This standardized NWB format enables reproducible analysis of motor cortex function in parkinsonian primates and facilitates comparison with other neurophysiology datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turner-lab-to-nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
