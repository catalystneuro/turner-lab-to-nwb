{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turner Lab M1 MPTP Dataset - NWB Usage Guide\n",
    "\n",
    "**Dataset Overview:**\n",
    "This dataset contains single-unit electrophysiology recordings from primary motor cortex (M1) of parkinsonian macaque monkeys performing flexion/extension motor tasks. The data investigates motor encoding deficits in MPTP-induced parkinsonism, comparing pyramidal tract neurons (PTNs) versus corticostriatal neurons (CSNs).\n",
    "\n",
    "**Key Features:**\n",
    "- **Single-unit recordings**: Spike times and waveforms from M1 neurons\n",
    "- **Motor behavior**: Flexion/extension task with analog kinematics\n",
    "- **Cell type identification**: Antidromic stimulation to classify PTNs vs CSNs\n",
    "- **Disease model**: MPTP-treated parkinsonian macaque monkeys\n",
    "- **Electrode mapping**: Systematic cortical penetrations with stereotactic coordinates\n",
    "\n",
    "**Data Organization:**\n",
    "- Each NWB file represents one recording session from one penetration depth\n",
    "- Session IDs follow pattern: `{Animal}++{FileName}++{PreMPTP|PostMPTP}++Depth{depth_um}um++{YearMonthDay}`\n",
    "- Example: `V++{v0502}++PostMPTP++Depth19180um++20000121` indicates monkey V, post-MPTP condition, 19.18mm depth, recorded Jan 21, 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NWB Files\n",
    "\n",
    "For now, we'll demonstrate loading files locally. In the future, these will be available for streaming via DANDI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import remfile\n",
    "from pynwb import NWBHDF5IO\n",
    "from dandi.dandiapi import DandiAPIClient\n",
    "\n",
    "# Connect to DANDI and get the dandiset\n",
    "dandiset_id = \"001636\"\n",
    "client = DandiAPIClient()\n",
    "dandiset = client.get_dandiset(dandiset_id, \"draft\")\n",
    "\n",
    "assets = dandiset.get_assets()\n",
    "assets_list = list(assets)\n",
    "\n",
    "\n",
    "asset = assets_list[0]\n",
    "\n",
    "s3_url = asset.get_content_url(follow_redirects=1, strip_query=False)\n",
    "file_system = remfile.File(s3_url)\n",
    "file = h5py.File(file_system, mode=\"r\")\n",
    "\n",
    "io = NWBHDF5IO(file=file)\n",
    "nwbfile = io.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nwbfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Electrode Configuration and Recording Setup\n",
    "\n",
    "The dataset includes both recording and stimulation electrodes with detailed anatomical information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine electrode configuration\n",
    "from pynwb import read_nwb\n",
    "\n",
    "electrodes_df = nwbfile.electrodes.to_dataframe()\n",
    "print(\"Electrode Configuration:\")\n",
    "print(f\"Total electrodes: {len(electrodes_df)}\")\n",
    "print(f\"Recording electrodes: {len(electrodes_df[~electrodes_df['is_stimulation']])}\")\n",
    "print(f\"Stimulation electrodes: {len(electrodes_df[electrodes_df['is_stimulation']])}\")\n",
    "\n",
    "print(\"\\nRecording electrode details:\")\n",
    "recording_electrode = electrodes_df[~electrodes_df['is_stimulation']].iloc[0]\n",
    "print(f\"  Chamber coordinates: A/P={recording_electrode['chamber_grid_ap_mm']:.2f}mm, M/L={recording_electrode['chamber_grid_ml_mm']:.2f}mm\")\n",
    "print(f\"  Insertion depth: {recording_electrode['chamber_insertion_depth_mm']:.2f}mm\")\n",
    "print(f\"  Recording site index: {recording_electrode['recording_site_index']}\")\n",
    "print(f\"  Recording session index: {recording_electrode['recording_session_index']}\")\n",
    "\n",
    "print(\"\\nStimulation electrodes:\")\n",
    "stim_electrodes = electrodes_df[electrodes_df['is_stimulation']]\n",
    "for _, electrode in stim_electrodes.iterrows():\n",
    "    print(f\"  {electrode['location']}: {electrode['stim_notes']}\")\n",
    "\n",
    "# Display electrode table\n",
    "electrodes_df[['location', 'group_name', 'is_stimulation', 'chamber_grid_ap_mm', 'chamber_grid_ml_mm', 'chamber_insertion_depth_mm']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrodes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trial Structure and Motor Behavior\n",
    "\n",
    "First, let's examine the experimental trials which provide the temporal structure for all other analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze trial structure\n",
    "trials_df = nwbfile.trials.to_dataframe()\n",
    "print(f\"Number of trials: {len(trials_df)}\")\n",
    "print(\"\\nTrial metadata columns:\")\n",
    "for col in trials_df.columns:\n",
    "    print(f\"  {col}\")\n",
    "\n",
    "# Display trials table\n",
    "trials_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single-Unit Activity Analysis\n",
    "\n",
    "Now let's examine the single-unit spike data and how it relates to the trial structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine units table\n",
    "units_df = nwbfile.units.to_dataframe()\n",
    "units_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trialized Spike Analysis\n",
    "\n",
    "Let's analyze spikes within the context of behavioral trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialized spike analysis\n",
    "unit_id = 0\n",
    "spike_times = nwbfile.units['spike_times'][unit_id]\n",
    "\n",
    "print(f\"Unit {unit_id} analysis:\")\n",
    "print(f\"  Total spikes: {len(spike_times)}\")\n",
    "print(f\"  Recording duration: {spike_times[-1] - spike_times[0]:.2f} seconds\")\n",
    "print(f\"  Mean firing rate: {len(spike_times) / (spike_times[-1] - spike_times[0]):.2f} Hz\")\n",
    "\n",
    "# Create trial-aligned spike raster\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Trial-aligned spike raster\n",
    "trial_spikes = []\n",
    "for trial_idx, trial in trials_df.iterrows():\n",
    "    trial_start = trial['start_time']\n",
    "    trial_stop = trial['stop_time']\n",
    "    \n",
    "    # Find spikes within this trial\n",
    "    trial_spike_times = spike_times[(spike_times >= trial_start) & (spike_times <= trial_stop)]\n",
    "    \n",
    "    # Convert to trial-relative times\n",
    "    relative_spike_times = trial_spike_times - trial_start\n",
    "    trial_spikes.append(relative_spike_times)\n",
    "    \n",
    "    # Plot spikes for this trial\n",
    "    if len(relative_spike_times) > 0:\n",
    "        ax1.scatter(relative_spike_times, np.full(len(relative_spike_times), trial_idx), \n",
    "                   s=1, color='black', alpha=0.7)\n",
    "\n",
    "ax1.set_xlabel('Time relative to trial start (s)')\n",
    "ax1.set_ylabel('Trial number')\n",
    "ax1.set_title('Trial-aligned spike raster')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# PSTH across trials\n",
    "# Bin spikes relative to trial start\n",
    "bin_size = 0.1  # 100ms bins\n",
    "max_trial_duration = trials_df['stop_time'].max() - trials_df['start_time'].min()\n",
    "bins = np.arange(0, max_trial_duration + bin_size, bin_size)\n",
    "\n",
    "# Collect all trial-relative spike times\n",
    "all_relative_spikes = np.concatenate([spikes for spikes in trial_spikes if len(spikes) > 0])\n",
    "\n",
    "if len(all_relative_spikes) > 0:\n",
    "    counts, _ = np.histogram(all_relative_spikes, bins=bins)\n",
    "    firing_rate = counts / (bin_size * len(trials_df))  # Average across trials\n",
    "    \n",
    "    ax2.plot(bins[:-1], firing_rate, linewidth=2)\n",
    "    ax2.set_xlabel('Time relative to trial start (s)')\n",
    "    ax2.set_ylabel('Firing rate (Hz)')\n",
    "    ax2.set_title('Peri-stimulus time histogram (PSTH)')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nTrialized analysis:\")\n",
    "print(f\"  Trials with spikes: {sum(1 for spikes in trial_spikes if len(spikes) > 0)}/{len(trials_df)}\")\n",
    "print(f\"  Mean spikes per trial: {np.mean([len(spikes) for spikes in trial_spikes]):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trialized Kinematic Analysis (TimeSeriesElbowVelocity)\n",
    "\n",
    "Now let's examine how the kinematic data aligns with trials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trialized kinematic analysis\n",
    "# Find TimeSeriesElbowVelocity\n",
    "elbow_velocity_series = nwbfile.acquisition['TimeSeriesElbowVelocity']\n",
    "\n",
    "print(f\"Kinematic data: {elbow_velocity_series.name}\")\n",
    "print(f\"  Description: {elbow_velocity_series.description}\")\n",
    "print(f\"  Data shape: {elbow_velocity_series.data.shape}\")\n",
    "print(f\"  Sampling rate: {elbow_velocity_series.rate} Hz\")\n",
    "print(f\"  Duration: {elbow_velocity_series.data.shape[0] / elbow_velocity_series.rate:.2f} seconds\")\n",
    "\n",
    "# Extract trial-aligned kinematic data\n",
    "kinematic_data = elbow_velocity_series.data[:]\n",
    "sampling_rate = elbow_velocity_series.rate\n",
    "\n",
    "# Plot trial-aligned kinematics\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "trial_kinematics = []\n",
    "for trial_idx, trial in trials_df.iterrows():\n",
    "    trial_start = trial['start_time']\n",
    "    trial_stop = trial['stop_time']\n",
    "    \n",
    "    # Convert trial times to sample indices\n",
    "    start_sample = int(trial_start * sampling_rate)\n",
    "    stop_sample = int(trial_stop * sampling_rate)\n",
    "    \n",
    "    # Extract kinematic data for this trial\n",
    "    trial_data = kinematic_data[start_sample:stop_sample]\n",
    "    trial_time = np.arange(len(trial_data)) / sampling_rate\n",
    "    \n",
    "    trial_kinematics.append(trial_data)\n",
    "    \n",
    "    # Plot individual trial (show first 10 trials)\n",
    "    if trial_idx < 10:\n",
    "        ax1.plot(trial_time, trial_data, alpha=0.7, linewidth=1, label=f'Trial {trial_idx+1}')\n",
    "\n",
    "ax1.set_xlabel('Time relative to trial start (s)')\n",
    "ax1.set_ylabel('Elbow Velocity')\n",
    "ax1.set_title('Trial-aligned Elbow Velocity (first 10 trials)')\n",
    "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Average across trials\n",
    "# Find minimum trial length for alignment\n",
    "min_trial_length = min(len(trial_data) for trial_data in trial_kinematics)\n",
    "\n",
    "# Truncate all trials to minimum length and average\n",
    "aligned_trials = np.array([trial_data[:min_trial_length] for trial_data in trial_kinematics])\n",
    "mean_kinematic = np.mean(aligned_trials, axis=0)\n",
    "std_kinematic = np.std(aligned_trials, axis=0)\n",
    "\n",
    "time_axis = np.arange(min_trial_length) / sampling_rate\n",
    "\n",
    "ax2.plot(time_axis, mean_kinematic, 'b-', linewidth=2, label='Mean')\n",
    "ax2.fill_between(time_axis, \n",
    "                mean_kinematic - std_kinematic, \n",
    "                mean_kinematic + std_kinematic, \n",
    "                alpha=0.3, color='blue', label='±1 SD')\n",
    "ax2.set_xlabel('Time relative to trial start (s)')\n",
    "ax2.set_ylabel('Elbow Velocity')\n",
    "ax2.set_title('Average trial-aligned Elbow Velocity')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\\\nTrialized kinematic analysis:\")\n",
    "print(f\"  Number of trials: {len(trial_kinematics)}\")\n",
    "print(f\"  Average trial duration: {np.mean([len(trial)/sampling_rate for trial in trial_kinematics]):.2f} seconds\")\n",
    "print(f\"  Kinematic range: {np.min(kinematic_data):.2f} to {np.max(kinematic_data):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Waveform Analysis\n",
    "\n",
    "Examine spike waveform characteristics for unit classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze spike waveforms\n",
    "unit_id = 0\n",
    "\n",
    "# Get waveform data\n",
    "waveform_mean = nwbfile.units['waveform_mean'][unit_id]\n",
    "waveform_sd = nwbfile.units['waveform_sd'][unit_id]\n",
    "\n",
    "# Create time axis (20kHz sampling, 1.6ms window)\n",
    "sampling_rate = 20000  # Hz\n",
    "n_samples = len(waveform_mean)\n",
    "time_axis = np.arange(n_samples) / sampling_rate * 1000  # Convert to milliseconds\n",
    "\n",
    "# Plot waveform with error bars\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_axis, waveform_mean, 'b-', linewidth=2, label='Mean waveform')\n",
    "plt.fill_between(time_axis, \n",
    "                    waveform_mean - waveform_sd, \n",
    "                    waveform_mean + waveform_sd, \n",
    "                    alpha=0.3, color='blue', label='±1 SD')\n",
    "\n",
    "plt.xlabel('Time (ms)')\n",
    "plt.ylabel('Voltage (μV)')\n",
    "plt.title(f'Unit {unit_id} - Mean Spike Waveform')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Add waveform characteristics\n",
    "duration = nwbfile.units['waveform_duration_ms'][unit_id]\n",
    "cell_type = nwbfile.units['cell_type'][unit_id]\n",
    "\n",
    "plt.text(0.7, 0.95, f'Duration: {duration:.2f} ms', \n",
    "        transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "plt.text(0.7, 0.85, f'Cell type: {cell_type}', \n",
    "        transform=plt.gca().transAxes, bbox=dict(boxstyle='round', facecolor='white', alpha=0.8))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antidromic Stimulation Analysis\n",
    "\n",
    "Examine the antidromic stimulation data used for cell type identification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze antidromic stimulation data\n",
    "antidromic_module = nwbfile.processing['antidromic_identification']\n",
    "print(f\"Antidromic identification module found\")\n",
    "print(f\"Description: {antidromic_module.description}\")\n",
    "\n",
    "# Find stimulation and response series\n",
    "stim_series = []\n",
    "response_series = []\n",
    "\n",
    "for name, obj in antidromic_module.data_interfaces.items():\n",
    "    if 'Stimulation' in name:\n",
    "        stim_series.append((name, obj))\n",
    "    elif 'Response' in name:\n",
    "        response_series.append((name, obj))\n",
    "\n",
    "print(f\"\\\\nFound {len(stim_series)} stimulation series and {len(response_series)} response series\")\n",
    "\n",
    "# Plot one stimulation-response pair\n",
    "stim_name, stim_data = stim_series[0]\n",
    "resp_name, resp_data = response_series[0]\n",
    "\n",
    "print(f\"\\\\nAnalyzing: {stim_name} and {resp_name}\")\n",
    "\n",
    "# Get a small segment for visualization (first 5 sweeps)\n",
    "n_samples_per_sweep = 1000  # 50ms at 20kHz\n",
    "n_sweeps_to_plot = 5\n",
    "\n",
    "stim_segment = stim_data.data[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "resp_segment = resp_data.data[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "time_segment = stim_data.timestamps[:n_samples_per_sweep * n_sweeps_to_plot]\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot stimulation current\n",
    "ax1.plot(time_segment, stim_segment * 1e6, 'r-', linewidth=1)  # Convert to μA\n",
    "ax1.set_ylabel('Stimulation Current (μA)')\n",
    "ax1.set_title(f'{stim_name} - First {n_sweeps_to_plot} sweeps')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot neural response\n",
    "ax2.plot(time_segment, resp_segment * 1e6, 'b-', linewidth=1)  # Convert to μV\n",
    "ax2.set_ylabel('Neural Response (μV)')\n",
    "ax2.set_xlabel('Time (s)')\n",
    "ax2.set_title(f'{resp_name} - First {n_sweeps_to_plot} sweeps')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Stimulation data shape: {stim_data.data.shape}\")\n",
    "print(f\"Response data shape: {resp_data.data.shape}\")\n",
    "print(f\"Stimulation placed at: {stim_data.timestamps[0]:.1f} seconds after session start\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Data Analysis: Spike-Triggered Averages\n",
    "\n",
    "Demonstrate how to combine multiple data streams for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create spike-triggered average of kinematic data\n",
    "unit_id = 0\n",
    "spike_times = nwbfile.units['spike_times'][unit_id]\n",
    "\n",
    "# Get kinematic data\n",
    "kinematic_series = nwbfile.acquisition['TimeSeriesElbowVelocity']\n",
    "\n",
    "# Parameters for spike-triggered average\n",
    "window_size = 0.5  # ±500ms around each spike\n",
    "sampling_rate = kinematic_series.rate\n",
    "window_samples = int(window_size * sampling_rate)\n",
    "\n",
    "# Get kinematic data\n",
    "kinematic_data = kinematic_series.data[:]\n",
    "\n",
    "# Extract windows around spikes\n",
    "sta_windows = []\n",
    "\n",
    "for spike_time in spike_times:\n",
    "    spike_sample = int(spike_time * sampling_rate)\n",
    "    \n",
    "    # Check if window fits within data\n",
    "    if (spike_sample - window_samples >= 0 and \n",
    "        spike_sample + window_samples < len(kinematic_data)):\n",
    "        \n",
    "        window = kinematic_data[spike_sample - window_samples:spike_sample + window_samples + 1]\n",
    "        sta_windows.append(window)\n",
    "\n",
    "sta_windows = np.array(sta_windows)\n",
    "\n",
    "# Calculate mean and standard error\n",
    "sta_mean = np.mean(sta_windows, axis=0)\n",
    "sta_sem = np.std(sta_windows, axis=0) / np.sqrt(len(sta_windows))\n",
    "\n",
    "# Create time axis\n",
    "time_axis = np.linspace(-window_size, window_size, len(sta_mean))\n",
    "\n",
    "# Plot spike-triggered average\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(time_axis, sta_mean, 'b-', linewidth=2, label='Mean')\n",
    "plt.fill_between(time_axis, \n",
    "               sta_mean - sta_sem, \n",
    "               sta_mean + sta_sem, \n",
    "               alpha=0.3, color='blue', label='±SEM')\n",
    "\n",
    "plt.axvline(0, color='red', linestyle='--', alpha=0.7, label='Spike time')\n",
    "plt.xlabel('Time relative to spike (s)')\n",
    "plt.ylabel('Elbow Velocity')\n",
    "plt.title(f'Spike-Triggered Average (Unit {unit_id}, n={len(sta_windows)} spikes)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Analyzed {len(sta_windows)} spikes out of {len(spike_times)} total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrates the key data types and analysis approaches for the Turner Lab M1 MPTP dataset:\n",
    "\n",
    "**Data Types Covered:**\n",
    "1. **Electrode configuration**: Recording and stimulation electrode setup with anatomical coordinates\n",
    "2. **Single-unit activity**: Spike times, waveforms, and cell type classification\n",
    "3. **Motor behavior**: Trial structure and analog kinematic recordings\n",
    "4. **Antidromic stimulation**: Electrical stimulation protocols for cell type identification\n",
    "5. **Cross-modal analysis**: Combining spike times with kinematic data\n",
    "\n",
    "**Key Features:**\n",
    "- All temporal data maintains original accuracy within each session\n",
    "- Systematic electrode mapping with chamber-relative coordinates\n",
    "- Cell type identification through antidromic stimulation\n",
    "- Motor task data for studying parkinsonian deficits\n",
    "- Rich metadata for experimental context\n",
    "\n",
    "**Temporal Limitations (Important):**\n",
    "- Session start times are set to midnight with systematic offsets for same-day recordings\n",
    "- Inter-trial intervals use fixed 3-second separation (not original behavioral timing)\n",
    "- All relative timing within sessions maintains original accuracy\n",
    "\n",
    "This standardized NWB format enables reproducible analysis of motor cortex function in parkinsonian primates and facilitates comparison with other neurophysiology datasets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "turner-lab-to-nwb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
